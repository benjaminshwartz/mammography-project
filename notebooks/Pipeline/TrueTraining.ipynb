{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bd0141a-3614-4403-b377-b11ee855f75a",
   "metadata": {},
   "source": [
    "MODULE DOWNLOADS (IMPORTANT TO HAVE PYTORCH THAT IS CUDA COMPATIBLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c949bc01-d832-4459-8ab9-7ad7b90ae794",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Requirement already satisfied: pydicom in /opt/conda/lib/python3.7/site-packages (2.3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Requirement already satisfied: torchmetrics in /opt/conda/lib/python3.7/site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (1.21.6)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (20.1)\n",
      "Requirement already satisfied: torch>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (1.11.0+cu113)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (4.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->torchmetrics) (2.4.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging->torchmetrics) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
      "Requirement already satisfied: torch==1.11.0+cu113 in /opt/conda/lib/python3.7/site-packages (1.11.0+cu113)\n",
      "Requirement already satisfied: torchvision==0.12.0+cu113 in /opt/conda/lib/python3.7/site-packages (0.12.0+cu113)\n",
      "Requirement already satisfied: torchaudio==0.11.0 in /opt/conda/lib/python3.7/site-packages (0.11.0+cu113)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.11.0+cu113) (4.4.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==0.12.0+cu113) (1.21.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.12.0+cu113) (9.3.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision==0.12.0+cu113) (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0+cu113) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0+cu113) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0+cu113) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision==0.12.0+cu113) (2022.9.24)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pydicom\n",
    "%pip install torchmetrics\n",
    "%pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11f5aa2-2ab8-4ded-9ce1-d101be700e01",
   "metadata": {},
   "source": [
    "MORE GENERIC PREPROCESSING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dde0202-1850-4071-b83b-348f7662cdb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF UNDOWNLOADED DATA: 0\n",
      "NUMBER OF ISSUES: 0\n"
     ]
    }
   ],
   "source": [
    "s3 = boto.client('s3')\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = 'mammographydata'\n",
    "key_prefix = 'DataSet/processed/'\n",
    "download_area = 'all_data' \n",
    "paginator = s3.get_paginator('list_objects_v2')\n",
    "pages = paginator.paginate(Bucket= bucket, Prefix= key_prefix)\n",
    "i = 0\n",
    "j = 0\n",
    "labels = pickle.load(open('label_dict.pt', 'rb'))\n",
    "undownloaded_list = []\n",
    "for label in labels.keys():\n",
    "    if label not in os.listdir('all_data'):\n",
    "        i += 1\n",
    "    files = os.listdir(f'all_data/{label}')\n",
    "    if  'LCC.pt' not in files or 'LMLO.pt' not in files or 'RCC_flipped.pt' not in files or 'RMLO_flipped.pt' not in files:\n",
    "        print(label)\n",
    "        j += 1\n",
    "        undownloaded_list.append(label)\n",
    "print(f'NUMBER OF UNDOWNLOADED DATA: {i}')\n",
    "print(f'NUMBER OF ISSUES: {j}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c4d03f-3b7b-4b08-83fd-64619458a3e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget https://mammographydata.s3.amazonaws.com/totaldata.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47978fa0-8c27-43b9-9c0f-90bba63e34d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!unzip -q totaldata.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4550c5-2ef1-49ef-a0c8-dbd79d88390d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'parent/breast-level_annotations.csv')\n",
    "df = df[(df['height'] == 3518) & (df['width'] == 2800)]\n",
    "df = df[~df['study_id'].isin(['dbca9d28baa3207b3187c4d07dc81a80'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204aeb08-d942-4d35-b4dd-ee8a0802503a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_zeros(data):\n",
    "    x , y = data.shape\n",
    "    zero_t = torch.tensor(0)\n",
    "    if x != 3500:\n",
    "        diff = x - 3500\n",
    "        i = 0\n",
    "        j = 0\n",
    "        k = 0\n",
    "        while k != diff:\n",
    "            #print(f'in loop {k} time on same data')\n",
    "            if (torch.count_nonzero(data[:i,:]) == zero_t):\n",
    "                i += 1\n",
    "            if (torch.count_nonzero(data[x-j:x,:] == zero_t)):\n",
    "                j += 1\n",
    "            k += 1\n",
    "            \n",
    "        if i + j != diff:\n",
    "            #print('There was an issue')\n",
    "            i = 0\n",
    "            j = diff\n",
    "            \n",
    "            \n",
    "    return data[i:x-j,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32e859e-01c6-4f1e-b6d7-b7d7150f884c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_client = boto.client('s3')\n",
    "for patient in undownloaded_list:\n",
    "    #print(patient)\n",
    "    curr_df = df[df['study_id'] == patient]\n",
    "    lmlo_image_id = list(curr_df[((curr_df['laterality'] == 'L') & (\n",
    "        curr_df['view_position'] == 'MLO'))]['image_id'])[0]\n",
    "    lcc_image_id = list(curr_df[((curr_df['laterality'] == 'L') & (\n",
    "        curr_df['view_position'] == 'CC'))]['image_id'])[0]\n",
    "    rmlo_image_id = list(curr_df[((curr_df['laterality'] == 'R') & (\n",
    "        curr_df['view_position'] == 'MLO'))]['image_id'])[0]\n",
    "    rcc_image_id = list(curr_df[((curr_df['laterality'] == 'R') & (\n",
    "        curr_df['view_position'] == 'CC'))]['image_id'])[0]\n",
    "\n",
    "    lmlo_dicom = dicom.dcmread(f'parent/images/{patient}/{lmlo_image_id}.dicom')\n",
    "    lcc_dicom = dicom.dcmread(f'parent/images/{patient}/{lcc_image_id}.dicom')\n",
    "    rmlo_dicom = dicom.dcmread(f'parent/images/{patient}/{rmlo_image_id}.dicom')\n",
    "    rcc_dicom = dicom.dcmread(f'parent/images/{patient}/{rcc_image_id}.dicom')\n",
    "    \n",
    "\n",
    "    lmlo_torch = find_zeros(torch.from_numpy(np.array(lmlo_dicom.pixel_array, dtype= np.float32)))\n",
    "    lcc_torch = find_zeros(torch.from_numpy(np.array(lcc_dicom.pixel_array, dtype = np.float32)))\n",
    "    rmlo_torch = find_zeros(torch.flip(torch.from_numpy(np.array(rmlo_dicom.pixel_array, dtype = np.float32)),(1,)))\n",
    "    rcc_torch = find_zeros(torch.flip(torch.from_numpy(np.array(rcc_dicom.pixel_array, dtype= np.float32)),(1,)))\n",
    "    \n",
    "    pickle.dump(lmlo_torch, open(f'upload/{patient}_LMLO.pt', \"wb\"))\n",
    "    pickle.dump(lcc_torch, open(f'upload/{patient}_LCC.pt', \"wb\"))\n",
    "    pickle.dump(rmlo_torch, open(f'upload/{patient}_RMLO_flipped.pt', \"wb\"))\n",
    "    pickle.dump(rcc_torch, open(f'upload/{patient}_RCC_flipped.pt', \"wb\"))\n",
    "    \n",
    "    s3_client.upload_file(f'upload/{patient}_LMLO.pt', 'mammographydata', f'DataSet/processed/{patient}/LMLO.pt')\n",
    "    s3_client.upload_file(f'upload/{patient}_LCC.pt', 'mammographydata', f'DataSet/processed/{patient}/LCC.pt')\n",
    "    s3_client.upload_file(f'upload/{patient}_RMLO_flipped.pt', 'mammographydata', f'DataSet/processed/{patient}/RMLO_flipped.pt')\n",
    "    s3_client.upload_file(f'upload/{patient}_RCC_flipped.pt', 'mammographydata', f'DataSet/processed/{patient}/RCC_flipped.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175a24c5-8373-426d-bb7d-76221a29b71e",
   "metadata": {},
   "source": [
    "GETTING DATA FROM BUCKET INTO CORRECT PROPER LOCAL DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11892ebb-997e-40b5-ae81-2e34e513d179",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Get Data In Local Directory\n",
    "s3 = boto.client('s3')\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = 'mammographydata'\n",
    "key_prefix = 'DataSet/processed/'\n",
    "download_area = 'all_data' \n",
    "paginator = s3.get_paginator('list_objects_v2')\n",
    "pages = paginator.paginate(Bucket= bucket, Prefix= key_prefix)\n",
    "file_num = 0\n",
    "page_num = 0\n",
    "for page in pages:\n",
    "    response = page['Contents']\n",
    "    response = response[1:]\n",
    "    for file in response:\n",
    "        key = file['Key'].split('/')\n",
    "        patient_ID = key[2]\n",
    "        view = key[3]\n",
    "        download_path = f'{download_area}/{patient_ID}'\n",
    "        specific_prefix = f'{key_prefix}{patient_ID}/{view}'\n",
    "        sagemaker_session.download_data(download_path, bucket, specific_prefix, extra_args=None)\n",
    "        file_num += 1\n",
    "        if file_num % 400 == 0:\n",
    "            print(f'On file num: {file_num}')\n",
    "    print(f'On Page: {page_num}')\n",
    "    page_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e9c066-2df1-4276-b935-1a00ed01ccad",
   "metadata": {},
   "source": [
    "BEGIN TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "656fc810-eb4a-44e6-80c7-7c35946d5fb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3 as boto\n",
    "import pickle\n",
    "import torch\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pydicom as dicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494f408d-c21f-41f7-9236-cc4892a10864",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mammography_project.src.models import data\n",
    "from mammography_project.src.models import MyClasses\n",
    "from mammography_project.src.models import PaperModel\n",
    "from mammography_project.src.models import runners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8bb7d4-2d7a-40a8-b976-224e8c6cf3e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEN TEST GEN BEFORE: 762\n",
      "LEN TRAIN GEN BEFORE: 3048\n",
      "LEN TEST GEN: 760\n",
      "LEN TRAIN GEN: 3048\n",
      "Trying Batched\n",
      "Starting Training\n",
      "\t[GPU cuda] Epoch 1\n",
      "Have run 20 batches\n",
      "Have run 40 batches\n",
      "Have run 60 batches\n",
      "Have run 80 batches\n",
      "Have run 100 batches\n",
      "Have run 120 batches\n",
      "Have run 140 batches\n",
      "Have run 160 batches\n",
      "Have run 180 batches\n",
      "Have run 200 batches\n",
      "Have run 220 batches\n",
      "Have run 240 batches\n",
      "Have run 260 batches\n",
      "Have run 280 batches\n",
      "Have run 300 batches\n",
      "Have run 320 batches\n",
      "Have run 340 batches\n",
      "Have run 360 batches\n",
      "Have run 380 batches\n",
      "Have run 400 batches\n",
      "Have run 420 batches\n",
      "Have run 440 batches\n",
      "Have run 460 batches\n",
      "Have run 480 batches\n",
      "Have run 500 batches\n",
      "Have run 520 batches\n",
      "Have run 540 batches\n",
      "Have run 560 batches\n",
      "Have run 580 batches\n",
      "Have run 600 batches\n",
      "Have run 620 batches\n",
      "Have run 640 batches\n",
      "Have run 660 batches\n",
      "Have run 680 batches\n",
      "Have run 700 batches\n",
      "Have run 720 batches\n",
      "Have run 740 batches\n",
      "Have run 760 batches\n",
      "\tTrain Metrics (Training Data):\n",
      "\t\tOverall Loss: 0.956024706363678 = 728.4908447265625/762\n",
      "\t\tLeft Loss: 0.935592532157898 = 712.9215087890625/762\n",
      "\t\tRight Loss: 0.9764544367790222 = 744.0582885742188/762\n",
      "\t\tOverall Accuracy: 0.5216535433070866 = 1590/3048\n",
      "\t\tLeft Accuracy: 0.6791338582677166 = 2070/3048\n",
      "\t\tRight Accuracy: 0.7004593175853019 = 2135/3048\n",
      "\tTest Metrics:\n",
      "\t\tOverall Loss: 1.05032479763031 = 199.56170654296875/190\n",
      "\t\tLeft Loss: 0.9559598565101624 = 181.6323699951172/190\n",
      "\t\tRight Loss: 1.1446897983551025 = 217.4910430908203/190\n",
      "\t\tOverall Accuracy: 0.4776315789473684 = 363/760\n",
      "\t\tLeft Accuracy: 0.6605263157894737 = 502/760\n",
      "\t\tRight Accuracy: 0.6421052631578947 = 488/760\n",
      "\t[GPU cuda] Epoch 2\n",
      "Have run 20 batches\n",
      "Have run 40 batches\n",
      "Have run 60 batches\n",
      "Have run 80 batches\n",
      "Have run 100 batches\n",
      "Have run 120 batches\n",
      "Have run 140 batches\n",
      "Have run 160 batches\n",
      "Have run 180 batches\n",
      "Have run 200 batches\n",
      "Have run 220 batches\n",
      "Have run 240 batches\n",
      "Have run 260 batches\n",
      "Have run 280 batches\n",
      "Have run 300 batches\n",
      "Have run 320 batches\n",
      "Have run 340 batches\n",
      "Have run 360 batches\n",
      "Have run 380 batches\n",
      "Have run 400 batches\n",
      "Have run 420 batches\n",
      "Have run 440 batches\n",
      "Have run 460 batches\n",
      "Have run 480 batches\n",
      "Have run 500 batches\n",
      "Have run 520 batches\n",
      "Have run 540 batches\n",
      "Have run 560 batches\n",
      "Have run 580 batches\n",
      "Have run 600 batches\n",
      "Have run 620 batches\n",
      "Have run 640 batches\n",
      "Have run 660 batches\n",
      "Have run 680 batches\n",
      "Have run 700 batches\n",
      "Have run 720 batches\n",
      "Have run 740 batches\n",
      "Have run 760 batches\n",
      "\tTrain Metrics (Training Data):\n"
     ]
    }
   ],
   "source": [
    "PaperModel.main(batch_size = 4)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g5.4xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
